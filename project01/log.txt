BATCH_SIZE=64,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.1,LEARNING_RATE=0.001,OPTIMIZER=adam,DROPOUT=0.5
Test set: Average loss: 0.0067, Accuracy: 86.83%
BATCH_SIZE=32,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.1,LEARNING_RATE=0.001,OPTIMIZER=adam,DROPOUT=0.5
Test set: Average loss: 0.0124, Accuracy: 87.75%
BATCH_SIZE=32,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.0,LEARNING_RATE=0.001,OPTIMIZER=adam,DROPOUT=0.0 NO BATCH NORMALIZATION
Test set: Average loss: 0.0437, Accuracy: 78.86%
BATCH_SIZE=32,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.1,LEARNING_RATE=0.1,OPTIMIZER=sgd,DROPOUT=0.5
Test set: Average loss: 0.0125, Accuracy: 87.34%
BATCH_SIZE=32,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.1,LEARNING_RATE=0.001,OPTIMIZER=adam,DROPOUT=0.1
Test set: Average loss: 0.0140, Accuracy: 88.69%
BATCH_SIZE=32,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.1,LEARNING_RATE=0.001,OPTIMIZER=adam,DROPOUT=0.1
Test set: Average loss: 0.0171, Accuracy: 84.75%
BATCH_SIZE=32,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.1,LEARNING_RATE=0.001,OPTIMIZER=adam,DROPOUT=0.2
Test set: Average loss: 0.0141, Accuracy: 88.33%
BATCH_SIZE=16,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.1,LEARNING_RATE=0.001,OPTIMIZER=adam,DROPOUT=0.1
Test set: Average loss: 0.0278, Accuracy: 88.25%
BATCH_SIZE=32,EPOCHS=64,AUGEMENTATION_PERCENTAGE=0.1,LEARNING_RATE=0.001,OPTIMIZER=adam,DROPOUT=0.1
Test set: Average loss: 0.0151, Accuracy: 89.42%
BATCH_SIZE=32,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.1,LEARNING_RATE=0.01,OPTIMIZER=adam,DROPOUT=0.1
Test set: Average loss: 0.0183, Accuracy: 87.15%
BATCH_SIZE=32,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.5,LEARNING_RATE=0.01,OPTIMIZER=adam,DROPOUT=0.1
Test set: Average loss: 0.0131, Accuracy: 88.59%
BATCH_SIZE=32,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.1,LEARNING_RATE=0.001,OPTIMIZER=adam,DROPOUT=0.1
Test set: Average loss: 0.0155, Accuracy: 88.06%
BATCH_SIZE=128,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.1,LEARNING_RATE=0.001,OPTIMIZER=adam,DROPOUT=0.1
Test set: Average loss: 0.0039, Accuracy: 88.42%
BATCH_SIZE=64,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.2,LEARNING_RATE=0.001,OPTIMIZER=adam,DROPOUT=0.1 -> User this reference
Test set: Average loss: 0.0072, Accuracy: 89.01%
BATCH_SIZE=64,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.2,LEARNING_RATE=0.001,OPTIMIZER=adam,DROPOUT=0.2
Test set: Average loss: 0.0065, Accuracy: 88.56%
BATCH_SIZE=64,EPOCHS=256,AUGEMENTATION_PERCENTAGE=0.2,LEARNING_RATE=0.001,OPTIMIZER=adam,DROPOUT=0.1
Test set: Average loss: 0.0064, Accuracy: 91.11%
BATCH_SIZE=64,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.2,LEARNING_RATE=0.001,OPTIMIZER=adam,DROPOUT=0.01
Test set: Average loss: 0.0083, Accuracy: 88.16%

BATCH_SIZE=64,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.2,LEARNING_RATE=0.001,OPTIMIZER=adam,DROPOUT=0.1,SCHEDULER=STEPLR,STEP_SIZE=5,GAMMA=0.1
Test set: Average loss: 0.0056, Accuracy: 87.72%
BATCH_SIZE=64,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.2,LEARNING_RATE=0.001,OPTIMIZER=adam,DROPOUT=0.1,SCHEDULER=STEPLR,STEP_SIZE=16,GAMMA=0.1
Test set: Average loss: 0.0055, Accuracy: 90.22%
BATCH_SIZE=64,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.2,LEARNING_RATE=0.001,OPTIMIZER=adam,DROPOUT=0.1,SCHEDULER=STEPLR,STEP_SIZE=8,GAMMA=0.1
Test set: Average loss: 0.0052, Accuracy: 89.46%
BATCH_SIZE=64,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.2,LEARNING_RATE=0.001,OPTIMIZER=adam,DROPOUT=0.1,SCHEDULER=STEPLR,STEP_SIZE=4,GAMMA=0.1
Test set: Average loss: 0.0063, Accuracy: 86.21%
BATCH_SIZE=64,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.2,LEARNING_RATE=0.001,OPTIMIZER=adam,DROPOUT=0.1,SCHEDULER=LambdaLR,DECRESE_LR0.95
Test set: Average loss: 0.0061, Accuracy: 89.82%
BATCH_SIZE=64,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.2,LEARNING_RATE=0.1,OPTIMIZER=sgd,DROPOUT=0.1
Test set: Average loss: 0.0071, Accuracy: 88.19%
BATCH_SIZE=64,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.2,LEARNING_RATE=0.1,OPTIMIZER=sgd,DROPOUT=0.1,SCHEDULER=LambdaLR,DECRESE_LR0.95
Test set: Average loss: 0.0065, Accuracy: 89.53%
BATCH_SIZE=64,EPOCHS=32,AUGEMENTATION_PERCENTAGE=0.2,LEARNING_RATE=0.1,OPTIMIZER=sgd,DROPOUT=0.1,SCHEDULER=StepLR, STEP_SIZE=16, GAMMA=0.1
Test set: Average loss: 0.0059, Accuracy: 89.80%
